### Q 1 : What is gradient descent ?###

Gradient descent is a generic optimization algorithm cable for finding optimal solutions to a wide range of problems. The general idea of gradient descent is to tweak 
parameters iteratively in order to minimize the cost function. The rest of the answer is [here](https://www.youtube.com/watch?v=IHZwWFHWa-w&t=4s)

### Q 2 : What is feature engineering ? ###

Feature engineering is the process of transforming raw data into features that are suitable for machine learning models. In other words, it is the process of selecting, extracting, 
and transforming the most relevant features from the available data to build more accurate and efficient machine learning models.

The success of machine learning models heavily depends on the quality of the features used to train them. Feature engineering involves a set of techniques that enable us to create 
new features by combining or transforming the existing ones. These techniques help to highlight the most important patterns and relationships in the data, which in turn helps the 
machine learning model to learn from the data more effectively.

### Q 3 : What is feature mapping ? ###

Feature mapping is a technique used in data analysis and machine learning to transform input data from a lower-dimensional space to a higher-dimensional space, where it can be 
more easily analyzed or classified. The rest of the answer is [here](https://www.geeksforgeeks.org/feature-mapping/) 

### Q 4 : What is a neural network ? ###

Neural Network is a sophisticated architecture consist of a stack of layers and neurons in each layer. Neural Network is the mathematical functions which transfer input variables 
to the target variable and learn the patterns.

A Neural Network is basically a dense interconnection of layers, which are further made up of basic units called perceptrons. A perceptron consists of input terminals, the 
processing unit and the output terminals. The input terminals of a perceptron are connected to the output terminals of the preceding perceptrons. The rest of the answer is [here](https://www.youtube.com/watch?v=aircAruvnKk)

### Q 5 : Why do we need to perform normalization or feature scaling ? What are the different types of normalization ? Also what is z-score normalization ?###

Normalization or feature scaling is a way to make sure that features with very diverse ranges will proportionally impact the network performance. Without normalization, some 
features or variables might be ignored. For example, imagine that we want to predict the price of a car using two features such as the driven distance and the car’s age. 
The first feature’s range is in thousands whereas the second one is in the range of tens of years. Using the raw data for predicting the price of the car, the distance feature 
would outweigh the age feature significantly. Therefore, we should normalize these two features to get a more accurate prediction.

The different types of normalization are as follows : The rest of the answer is [here](https://medium.com/nerd-for-tech/overview-of-normalization-techniques-in-deep-learning-e12a79060daf)

Z-score normalization refers to the process of normalizing every value in a dataset such that the mean of all of the values is 0 and the standard deviation is 1. We use the 
following formula to perform a z-score normalization on every value in a dataset : `New value = (x – μ) / σ` where : `x: Original value, μ: Mean of data and σ: Standard deviation of data`

### Q 6 : What is the difference between normalization or feature scaling and standarization ? ###

Normalisation is suitable to use when the data does not follow Gaussian Distribution principles. It can be used in algorithms that do not assume data distribution, such as 
K-Nearest Neighbors and Neural Networks. The rest of the answer is [here](https://www.codingninjas.com/studio/library/normalisation-vs-standardisation). More visual 
understanding refer to this [link](https://www.youtube.com/watch?v=sxEqtjLC0aM)
